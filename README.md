# chat2db-internlm-deploy


è¯­è¨€ï¼šä¸­æ–‡  | [English](README_EN.md)

## ğŸ“– ç®€ä»‹
è¿™ä¸ªå·¥ç¨‹ä»‹ç»äº†å¦‚ä½•åœ¨[InternLM](https://github.com/InternLM/InternLM)çš„[InternStudio](https://studio.intern-ai.org.cn/)ä¸Šéƒ¨ç½²InternLMçš„å„ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼Œå¹¶å°†å¤§æ¨¡å‹åº”ç”¨åˆ°Chat2DBå®¢æˆ·ç«¯ä¸­ã€‚è¯»è€…ä¹Ÿå¯ä»¥è‡ªè¡Œé€‰æ‹©åˆé€‚çš„äº‘å¹³å°è¿›è¡Œéƒ¨ç½²ã€‚

æ„Ÿè°¢[InternLM](https://github.com/InternLM/InternLM)å¯¹æœ¬é¡¹ç›®çš„å¤§åŠ›æ”¯æŒï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨[InternLM](https://github.com/InternLM/InternLM)è·å–æ›´å¤šä¿¡æ¯ï¼Œåç»­ä¼šåœ¨æœ¬æ–‡æ¡£ä¸­é™†ç»­åŠ å…¥å¦‚ä½•å¾®è°ƒInternLMæ¨¡å‹çš„æ•™ç¨‹ã€‚

## ğŸ“¦ ç¡¬ä»¶è¦æ±‚
|      æ¨¡å‹       | æœ€ä½GPUæ˜¾å­˜(æ¨ç†) | æœ€ä½GPUæ˜¾å­˜(é«˜æ•ˆå‚æ•°å¾®è°ƒ) |
|:-------------:|:-----------:|:---------------:|
|  InternLM-7b  |    18GB     |      24GB       |
| InternLM2-7b  |    18GB     |      24GB       |
| InternLM-20b  |    42GB     |      58GB       |
| InternLM2-20b |    42GB     |      58GB       |


## ğŸ“¦ éƒ¨ç½²
### ğŸ“¦ åœ¨InternStudioä¸­éƒ¨ç½²InternLMæ¨¡å‹

1. å‰å¾€[InternStudioå¹³å°](https://studio.intern-ai.org.cn/)
2. åˆ›å»ºä¸€ä¸ªå¼€å‘æœºå®ä¾‹ï¼Œå¯ä»¥æ ¹æ®éœ€è¦çš„ç®—åŠ›é…ç½®å¼€å‘æœºçš„è§„æ ¼
   <img src="http://gpt.sqlgpt.cn/download/img/1.png">
   <img src="http://gpt.sqlgpt.cn/download/img/2.png">
   
3. è¿›å…¥å¼€å‘æœºåœ¨å¼€å‘æœºä¸Šæ‰“å¼€ä¸€ä¸ªç»ˆç«¯ï¼Œå®‰è£…[FastChat](https://github.com/lm-sys/FastChat)
```bash
conda create -n fastchat python=3.10 -y
conda activate fastchat
pip install "fschat[model_worker,webui]" -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install einops -i https://pypi.tuna.tsinghua.edu.cn/simple
```
4. æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ¥å¯åŠ¨InternLMæ¨¡å‹ï¼ŒInternLMå„ä¸ªç‰ˆæœ¬çš„æ¨¡å‹é»˜è®¤æ”¾åœ¨/root/share/model_repos/æ–‡ä»¶å¤¹ä¸‹ï¼Œå¯åŠ¨ä¸åŒçš„æ¨¡å‹åªéœ€ä¿®æ”¹å¦‚ä¸‹å‘½ä»¤ä¸­çš„æ¨¡å‹è·¯å¾„å³å¯ï¼Œå¦‚æœè¯»è€…æ˜¯ä½¿ç”¨çš„å…¶ä»–äº‘å¹³å°ï¼Œå¯ä»¥æ‰‹åŠ¨[ä¸‹è½½æ¨¡å‹](https://github.com/InternLM/InternLM)å¹¶å°†æ¨¡å‹æ”¾åœ¨ä»»æ„è·¯å¾„ä¸‹ï¼Œç„¶åä¿®æ”¹å¦‚ä¸‹å‘½ä»¤ä¸­çš„æ¨¡å‹è·¯å¾„å³å¯
```
python -m fastchat.serve.controller --host 0.0.0.0 --port 21001
python -m fastchat.serve.model_worker --model-path /root/share/model_repos/internlm2-7b --host 0.0.0.0
python -m fastchat.serve.test_message --model-name internlm2-7b
python3 -m fastchat.serve.openai_api_server --host 0.0.0.0 --port 8000
```
5.å‚è€ƒ[InternLMæ–‡æ¡£](https://aicarrier.feishu.cn/wiki/RkBWwdOfQiuLJHkEbqhceIRjnGg)å°†æœåŠ¡å™¨ä¸Šçš„8000ç«¯å£è½¬å‘åˆ°æœ¬åœ°å¼€å‘æœºçš„9990ç«¯å£
6.å‚è€ƒä¸‹å›¾é…ç½®Chat2DBå®¢æˆ·ç«¯ï¼Œå¦‚æœè¯»è€…æ˜¯éƒ¨ç½²çš„å…¶ä»–ç‰ˆæœ¬æ¨¡å‹ï¼Œå¯¹åº”çš„ä¿®æ”¹å¦‚ä¸‹æ¨¡å‹é…ç½®å³å¯
 <img src="http://gpt.sqlgpt.cn/download/img/4.png">
7.å¦‚ä¸Šé…ç½®å®¢æˆ·ç«¯ä¹‹åå³å¯æœ¬åœ°ä½“éªŒInternLMæ¨¡å‹çš„æ•ˆæœå•¦

## å¾®è°ƒ
### ğŸ“¦ åœ¨InternStudioä¸­å¾®è°ƒInternLMæ¨¡å‹

#### TODOï¼šå¾…æ·»åŠ 


